# LLMDialogSummarizer-QLoRA

This repository contains a **dialogue summarization model** fine-tuned using **QLoRA** on **Phi-2**. The model is optimized to generate concise and accurate summaries of conversational exchanges.

## Overview
- **Base Model:** Phi-2 (by Microsoft)
- **Fine-tuning Method:** QLoRA (Quantized Low-Rank Adapters)
- **Task:** Summarizing dialogues

## How It Works
QLoRA is a memory-efficient fine-tuning technique that enables training large language models on consumer-grade GPUs by using quantization and low-rank adapters. In this project, QLoRA was used to fine-tune **Phi-2** for **dialog summarization**.

